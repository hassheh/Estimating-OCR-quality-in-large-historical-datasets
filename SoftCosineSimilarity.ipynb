{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-452ce3d8f573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#download('stopwords')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "import nltk\n",
    "#download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perPageText = pd.read_csv('ReasearchProjectData/by_page_csv/0161600102_by_page.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aff4179d6cac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperPageText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlowers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperPageText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtcp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\w+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "i = 0\n",
    "while i < len(perPageText.tcp):\n",
    "    lowers = perPageText.tcp[i].lower()\n",
    "    tokens.append(nltk.RegexpTokenizer(r'\\w+').tokenize(lowers))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e08c50f639a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperPageText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mocr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlowers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperPageText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mocr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtokens_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\w+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "tokens_o = []\n",
    "i = 0\n",
    "while i < len(perPageText.ocr):\n",
    "    lowers = perPageText.ocr[i].lower()\n",
    "    tokens_o.append(nltk.RegexpTokenizer(r'\\w+').tokenize(lowers))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_4 = dictionary.doc2bow(tokens_o[0])\n",
    "sentence_5 = dictionary.doc2bow(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = api.load(\"glove-wiki-gigaword-50\")\n",
    "similarity_index = WordEmbeddingSimilarityIndex(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity = 0.9179\n"
     ]
    }
   ],
   "source": [
    "similarity = similarity_matrix.inner_product(sentence_5, sentence_4, normalized=True)\n",
    "print('similarity = %.4f' % similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ialciphron',\n",
       " 'or',\n",
       " 't',\n",
       " 'he',\n",
       " 'minute',\n",
       " 'philosopher',\n",
       " 'in',\n",
       " 'seven',\n",
       " 'dialogues',\n",
       " 'containing',\n",
       " 'a',\n",
       " 'apology',\n",
       " 'for',\n",
       " 'the',\n",
       " 'christian',\n",
       " 'religion',\n",
       " 'againjt',\n",
       " 'thobe',\n",
       " 'who',\n",
       " 'are',\n",
       " 'called',\n",
       " 'free',\n",
       " 'thinkers',\n",
       " 'volume',\n",
       " 'the',\n",
       " 'second',\n",
       " '2be',\n",
       " 'balances',\n",
       " 'of',\n",
       " 'deceit',\n",
       " 'are',\n",
       " 'in',\n",
       " 'his',\n",
       " 'hand',\n",
       " 'hosea',\n",
       " 'xii',\n",
       " '7',\n",
       " 'itoe',\n",
       " 'ec',\n",
       " 'tt',\n",
       " 'cttoy',\n",
       " 'i',\n",
       " 'j',\n",
       " 'ttg',\n",
       " 't',\n",
       " 'r',\n",
       " 'cylvy',\n",
       " 'asr7tat0ctov',\n",
       " 'plato',\n",
       " 'd',\n",
       " 'd',\n",
       " 'b',\n",
       " 'l',\n",
       " 'i',\n",
       " 'n',\n",
       " 'printed',\n",
       " 'for',\n",
       " 'g',\n",
       " 'risk',\n",
       " 'g',\n",
       " 'ewing',\n",
       " 'and',\n",
       " 'w',\n",
       " 'smith',\n",
       " 'booksellers',\n",
       " 'in',\n",
       " 'damne',\n",
       " 'street',\n",
       " 'mdccxxxii']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alciphron',\n",
       " 'or',\n",
       " 'the',\n",
       " 'minute',\n",
       " 'philosopher',\n",
       " 'in',\n",
       " 'seven',\n",
       " 'dialogues',\n",
       " 'containing',\n",
       " 'an',\n",
       " 'apology',\n",
       " 'for',\n",
       " 'the',\n",
       " 'chriÅ¿tian',\n",
       " 'religion',\n",
       " 'againÅ¿t',\n",
       " 'thoÅ¿e',\n",
       " 'who',\n",
       " 'are',\n",
       " 'called',\n",
       " 'free',\n",
       " 'thinkers',\n",
       " 'volume',\n",
       " 'the',\n",
       " 'second',\n",
       " 'the',\n",
       " 'balances',\n",
       " 'of',\n",
       " 'deceit',\n",
       " 'are',\n",
       " 'in',\n",
       " 'his',\n",
       " 'hand',\n",
       " 'hoÅ¿ea',\n",
       " 'xii',\n",
       " '7',\n",
       " 'in',\n",
       " 'non',\n",
       " 'latin',\n",
       " 'alphabet',\n",
       " 'plato',\n",
       " 'dublin',\n",
       " 'printed',\n",
       " 'for',\n",
       " 'g',\n",
       " 'risk',\n",
       " 'g',\n",
       " 'ewing',\n",
       " 'and',\n",
       " 'w',\n",
       " 'smith',\n",
       " 'bookÅ¿ellers',\n",
       " 'in',\n",
       " 'dame',\n",
       " 'street',\n",
       " 'mdccxxxii']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
